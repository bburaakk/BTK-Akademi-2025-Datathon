{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 112016,
          "databundleVersionId": 13341508,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "datathon_2025_2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bburaakk/BTK-Akademi-2025-Datathon/blob/main/datathon_2025_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "_0y3-WvMwN0J"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "datathon_2025_path = kagglehub.competition_download('datathon-2025')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "H6rhi_ZjwN0L"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KÃ¼tÃ¼phaneler"
      ],
      "metadata": {
        "id": "7QQTOjFVwN0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.decomposition import PCA\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"ğŸ“š TÃ¼m kÃ¼tÃ¼phaneler yÃ¼klendi!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:20:15.012326Z",
          "iopub.execute_input": "2025-08-31T12:20:15.012903Z",
          "iopub.status.idle": "2025-08-31T12:20:15.017982Z",
          "shell.execute_reply.started": "2025-08-31T12:20:15.012876Z",
          "shell.execute_reply": "2025-08-31T12:20:15.017233Z"
        },
        "id": "t0JLiUbgwN0N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.VERÄ° YÃœKLEME VE TEMEL TEMÄ°ZLEME"
      ],
      "metadata": {
        "id": "7Z24F__RwN0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 1. VERÄ° YÃœKLEME VE TEMEL TEMÄ°ZLEME\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ”„ Veri yÃ¼kleniyor...\")\n",
        "train = pd.read_csv(\"/kaggle/input/datathon-2025/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/datathon-2025/test.csv\")\n",
        "\n",
        "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
        "\n",
        "# Duplicated temizleme\n",
        "print(\"ğŸ§¹ Duplicate veriler temizleniyor...\")\n",
        "initial_rows = train.shape[0]\n",
        "train.drop_duplicates(inplace=True)\n",
        "print(f\"   {initial_rows - train.shape[0]} duplicate satÄ±r Ã§Ä±karÄ±ldÄ±\")\n",
        "\n",
        "# DateTime dÃ¶nÃ¼ÅŸÃ¼mÃ¼\n",
        "print(\"ğŸ“… Datetime formatÄ±na Ã§evriliyor...\")\n",
        "train['event_time'] = pd.to_datetime(train['event_time'])\n",
        "test['event_time'] = pd.to_datetime(test['event_time'])\n",
        "\n",
        "# Multi-user session temizleme\n",
        "def clean_multi_user_sessions(df, df_name):\n",
        "    session_user_counts = df.groupby('user_session')['user_id'].nunique()\n",
        "    problematic_sessions = session_user_counts[session_user_counts > 1].index.tolist()\n",
        "\n",
        "    if not problematic_sessions:\n",
        "        print(f\"   {df_name}: Sorunlu session yok\")\n",
        "        return df\n",
        "\n",
        "    print(f\"   {df_name}: {len(problematic_sessions)} sorunlu session dÃ¼zeltiliyor\")\n",
        "    correction_map = {}\n",
        "    for session_id in problematic_sessions:\n",
        "        mode_user_id = df[df['user_session'] == session_id]['user_id'].mode()[0]\n",
        "        correction_map[session_id] = mode_user_id\n",
        "\n",
        "    for session_id, correct_user_id in correction_map.items():\n",
        "        df.loc[df['user_session'] == session_id, 'user_id'] = correct_user_id\n",
        "\n",
        "    return df\n",
        "\n",
        "train = clean_multi_user_sessions(train, \"Train\")\n",
        "test = clean_multi_user_sessions(test, \"Test\")\n",
        "\n",
        "print(\"âœ… Temel temizleme tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:20:15.019228Z",
          "iopub.execute_input": "2025-08-31T12:20:15.019579Z",
          "iopub.status.idle": "2025-08-31T12:20:16.101993Z",
          "shell.execute_reply.started": "2025-08-31T12:20:15.019555Z",
          "shell.execute_reply": "2025-08-31T12:20:16.101171Z"
        },
        "id": "d5gqFFSlwN0Q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.DATA LEAK TESPÄ°TÄ° VE AYIRMA"
      ],
      "metadata": {
        "id": "Zu4LFuvSwN0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 2. DATA LEAK TESPÄ°TÄ° VE AYIRMA\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ•µï¸ Data leak tespiti...\")\n",
        "train_sessions = set(train['user_session'].unique())\n",
        "test_sessions = set(test['user_session'].unique())\n",
        "leaked_sessions = train_sessions.intersection(test_sessions)\n",
        "\n",
        "print(f\"   Leaked sessions: {len(leaked_sessions)}\")\n",
        "\n",
        "if len(leaked_sessions) > 0:\n",
        "    # Leak map oluÅŸtur\n",
        "    leaked_df_from_train = train[train['user_session'].isin(leaked_sessions)]\n",
        "    leak_map_df = leaked_df_from_train[['user_session', 'session_value']].drop_duplicates()\n",
        "    leak_map = pd.Series(leak_map_df.session_value.values,\n",
        "                        index=leak_map_df.user_session).to_dict()\n",
        "\n",
        "    # Test setini ayÄ±r\n",
        "    test_leaked_df = test[test['user_session'].isin(leaked_sessions)].copy()\n",
        "    test_unseen_df = test[~test['user_session'].isin(leaked_sessions)].copy()\n",
        "\n",
        "    print(f\"   Test leaked: {test_leaked_df.shape[0]}, Test unseen: {test_unseen_df.shape[0]}\")\n",
        "else:\n",
        "    leak_map = {}\n",
        "    test_unseen_df = test.copy()\n",
        "    print(\"   Leak bulunamadÄ±, tÃ¼m test verisi unseen olarak iÅŸleniyor\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:20:16.103417Z",
          "iopub.execute_input": "2025-08-31T12:20:16.103664Z",
          "iopub.status.idle": "2025-08-31T12:20:16.157078Z",
          "shell.execute_reply.started": "2025-08-31T12:20:16.103646Z",
          "shell.execute_reply": "2025-08-31T12:20:16.156501Z"
        },
        "id": "DN7ClCrPwN0S"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.GELÄ°ÅMÄ°Å FEATÃ¼RE ENGINEERÄ°NG"
      ],
      "metadata": {
        "id": "PPaJL0dEwN0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 3. GELÄ°ÅMÄ°Å FEATÃ¼RE ENGINEERÄ°NG\n",
        "# ===============================================================================\n",
        "\n",
        "def advanced_feature_engineering(df_train, df_test):\n",
        "    print(\"\\nğŸš€ GeliÅŸmiÅŸ Feature Engineering baÅŸlatÄ±lÄ±yor...\")\n",
        "\n",
        "    # Combine datasets\n",
        "    train_target = df_train[['user_session', 'session_value']].drop_duplicates()\n",
        "    df_train['is_train'] = 1\n",
        "    df_test['is_train'] = 0\n",
        "    df_full = pd.concat([df_train.drop('session_value', axis=1), df_test], ignore_index=True)\n",
        "\n",
        "    # 1. TEMEL Ã–ZELLÄ°KLER\n",
        "    print(\"   ğŸ“Š Temel Ã¶zellikler...\")\n",
        "    session_df = df_full.groupby('user_session').agg(\n",
        "        user_id=('user_id', 'first'),\n",
        "        is_train=('is_train', 'first'),\n",
        "        session_start_time=('event_time', 'min'),\n",
        "        session_end_time=('event_time', 'max'),\n",
        "        session_duration_seconds=('event_time', lambda x: (x.max() - x.min()).total_seconds()),\n",
        "        total_events=('event_type', 'count'),\n",
        "        unique_products=('product_id', 'nunique')\n",
        "    ).reset_index()\n",
        "\n",
        "    # 2. ZAMAN Ã–ZELLÄ°KLERÄ°\n",
        "    print(\"   â° Zaman Ã¶zellikleri...\")\n",
        "    session_df['start_hour'] = session_df['session_start_time'].dt.hour\n",
        "    session_df['day_of_week'] = session_df['session_start_time'].dt.dayofweek\n",
        "    session_df['is_weekend'] = (session_df['day_of_week'] >= 5).astype(int)\n",
        "    session_df['start_month'] = session_df['session_start_time'].dt.month\n",
        "\n",
        "    # Cyclical encoding\n",
        "    session_df['hour_sin'] = np.sin(2 * np.pi * session_df['start_hour'] / 24)\n",
        "    session_df['hour_cos'] = np.cos(2 * np.pi * session_df['start_hour'] / 24)\n",
        "    session_df['day_sin'] = np.sin(2 * np.pi * session_df['day_of_week'] / 7)\n",
        "    session_df['day_cos'] = np.cos(2 * np.pi * session_df['day_of_week'] / 7)\n",
        "\n",
        "    # 3. EVENT TYPE FEATURES\n",
        "    print(\"   ğŸ¯ Event type features...\")\n",
        "    event_counts = df_full.groupby('user_session')['event_type'].value_counts().unstack(fill_value=0)\n",
        "    event_counts.columns = [f'{col}_count' for col in event_counts.columns]\n",
        "    session_df = session_df.merge(event_counts, on='user_session', how='left')\n",
        "\n",
        "    # Ensure all event types\n",
        "    for event_type in ['VIEW', 'ADD_CART', 'REMOVE_CART', 'BUY']:\n",
        "        if f'{event_type}_count' not in session_df.columns:\n",
        "            session_df[f'{event_type}_count'] = 0\n",
        "\n",
        "    # Behavioral ratios\n",
        "    session_df['conversion_rate'] = session_df['BUY_count'] / (session_df['VIEW_count'] + 1)\n",
        "    session_df['cart_abandonment_rate'] = session_df['REMOVE_CART_count'] / (session_df['ADD_CART_count'] + 1)\n",
        "    session_df['add_to_cart_rate'] = session_df['ADD_CART_count'] / (session_df['VIEW_count'] + 1)\n",
        "    session_df['purchase_efficiency'] = session_df['BUY_count'] / (session_df['total_events'] + 1)\n",
        "\n",
        "    # 4. PRODUCT FEATURES\n",
        "    print(\"   ğŸ›ï¸ Product features...\")\n",
        "    product_stats = df_full.groupby('user_session').agg(\n",
        "        product_diversity=('product_id', lambda x: len(x.unique()) / len(x) if len(x) > 0 else 0),\n",
        "        product_revisit_rate=('product_id', lambda x: 1 - len(x.unique()) / len(x) if len(x) > 0 else 0)\n",
        "    )\n",
        "    session_df = session_df.merge(product_stats, on='user_session', how='left')\n",
        "\n",
        "    # 5. TF-IDF FEATURES (Simplified)\n",
        "    print(\"   ğŸ“ TF-IDF features...\")\n",
        "    train_session_texts = df_full[df_full['is_train'] == 1].groupby('user_session')['product_id'].apply(\n",
        "        lambda x: ' '.join(x.astype(str))\n",
        "    )\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=200, min_df=2)\n",
        "    tfidf_vectorizer.fit(train_session_texts)\n",
        "\n",
        "    all_session_texts = df_full.groupby('user_session')['product_id'].apply(\n",
        "        lambda x: ' '.join(x.astype(str))\n",
        "    )\n",
        "    tfidf_matrix = tfidf_vectorizer.transform(all_session_texts)\n",
        "\n",
        "    # PCA for dimensionality reduction\n",
        "    pca = PCA(n_components=30, random_state=42)\n",
        "    tfidf_pca = pca.fit_transform(tfidf_matrix.toarray())\n",
        "\n",
        "    tfidf_df = pd.DataFrame(tfidf_pca,\n",
        "                           index=all_session_texts.index,\n",
        "                           columns=[f'prod_pca_{i}' for i in range(30)])\n",
        "    session_df = session_df.merge(tfidf_df, on='user_session', how='left')\n",
        "\n",
        "    # 6. SEQUENCE FEATURES\n",
        "    print(\"   ğŸ”„ Sequence features...\")\n",
        "    def get_first_last_events(group):\n",
        "        events = group.sort_values('event_time')\n",
        "        return pd.Series({\n",
        "            'first_event': events['event_type'].iloc[0] if len(events) > 0 else 'VIEW',\n",
        "            'last_event': events['event_type'].iloc[-1] if len(events) > 0 else 'VIEW',\n",
        "            'event_diversity': len(events['event_type'].unique())\n",
        "        })\n",
        "\n",
        "    sequence_features = df_full.groupby('user_session').apply(get_first_last_events)\n",
        "    session_df = session_df.merge(sequence_features, on='user_session', how='left')\n",
        "\n",
        "    # 7. ENCODING - DÃ¼zeltilmiÅŸ\n",
        "    print(\"   ğŸ·ï¸ Encoding (DÃ¼zeltilmiÅŸ)...\")\n",
        "\n",
        "    # Split data back before encoding\n",
        "    train_session_df = session_df[session_df['is_train'] == 1].copy()\n",
        "    test_session_df = session_df[session_df['is_train'] == 0].copy()\n",
        "\n",
        "    # Fit encoders ONLY on train data\n",
        "    le_user = LabelEncoder()\n",
        "    train_session_df['user_id_encoded'] = le_user.fit_transform(train_session_df['user_id'])\n",
        "\n",
        "    le_first = LabelEncoder()\n",
        "    train_session_df['first_event_encoded'] = le_first.fit_transform(train_session_df['first_event'])\n",
        "\n",
        "    le_last = LabelEncoder()\n",
        "    train_session_df['last_event_encoded'] = le_last.fit_transform(train_session_df['last_event'])\n",
        "\n",
        "    # Transform test data - handle unseen categories\n",
        "    # For unseen categories in test, assign a value that will be treated as missing or a separate category by models\n",
        "    # Here, we will use -1 for simplicity, assuming models can handle it or we will one-hot encode later\n",
        "    # A more robust approach would involve mapping to a common 'unknown' category if one-hot encoding\n",
        "    def transform_with_unseen(le, series):\n",
        "        return series.map(lambda s: le.transform([s])[0] if s in le.classes_ else -1)\n",
        "\n",
        "    test_session_df['user_id_encoded'] = transform_with_unseen(le_user, test_session_df['user_id'])\n",
        "    test_session_df['first_event_encoded'] = transform_with_unseen(le_first, test_session_df['first_event'])\n",
        "    test_session_df['last_event_encoded'] = transform_with_unseen(le_last, test_session_df['last_event'])\n",
        "\n",
        "\n",
        "    # Duration segments (can be done on combined data as it's value-based)\n",
        "    session_df['duration_log'] = np.log1p(session_df['session_duration_seconds'])\n",
        "    session_df['duration_segment'] = pd.cut(session_df['session_duration_seconds'],\n",
        "                                           bins=[0, 60, 300, 1800, 7200, float('inf')],\n",
        "                                           labels=['Very_Short', 'Short', 'Medium', 'Long', 'Very_Long'],\n",
        "                                           right=False) # Use right=False for intervals [a, b)\n",
        "\n",
        "    # Merge duration features back\n",
        "    duration_features = session_df[['user_session', 'duration_log', 'duration_segment']]\n",
        "    train_session_df = train_session_df.merge(duration_features, on='user_session', how='left')\n",
        "    test_session_df = test_session_df.merge(duration_features, on='user_session', how='left')\n",
        "\n",
        "\n",
        "    # 8. CLEANUP\n",
        "    print(\"   ğŸ§¹ Temizlik...\")\n",
        "    # Drop original categorical columns and is_train\n",
        "    cols_to_drop = ['user_id', 'session_start_time', 'session_end_time',\n",
        "                    'first_event', 'last_event', 'is_train']\n",
        "\n",
        "    final_train_df = train_session_df.drop(cols_to_drop, axis=1)\n",
        "    final_test_df = test_session_df.drop(cols_to_drop, axis=1)\n",
        "\n",
        "    # Fill missing values (should be minimal after encoding fix, but keep as safety)\n",
        "    # Categorical columns with potential -1 from unseen should be handled by model or one-hot encoding\n",
        "    # Numeric columns should be filled, e.g., with 0 or mean/median of train data\n",
        "    numeric_cols_train = final_train_df.select_dtypes(include=np.number).columns\n",
        "    numeric_cols_test = final_test_df.select_dtypes(include=np.number).columns\n",
        "\n",
        "    # Fill numeric NaNs with 0 (or consider a better strategy like train mean/median)\n",
        "    final_train_df[numeric_cols_train] = final_train_df[numeric_cols_train].fillna(0)\n",
        "    final_test_df[numeric_cols_test] = final_test_df[numeric_cols_test].fillna(0)\n",
        "\n",
        "    # Handle 'duration_segment' - fill NaNs with a default category if any\n",
        "    if 'duration_segment' in final_train_df.columns:\n",
        "         final_train_df['duration_segment'] = final_train_df['duration_segment'].cat.add_categories('Unknown').fillna('Unknown')\n",
        "         final_test_df['duration_segment'] = final_test_df['duration_segment'].cat.add_categories('Unknown').fillna('Unknown')\n",
        "\n",
        "\n",
        "    # Merge target back to train\n",
        "    final_train_df = final_train_df.merge(train_target, on='user_session', how='left')\n",
        "\n",
        "    print(f\"   âœ… Feature engineering tamamlandÄ±! Train: {final_train_df.shape}, Test: {final_test_df.shape}\")\n",
        "    return final_train_df, final_test_df\n",
        "\n",
        "# Feature engineering Ã§alÄ±ÅŸtÄ±r\n",
        "train_features_df, test_features_df = advanced_feature_engineering(train, test_unseen_df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:20:16.157788Z",
          "iopub.execute_input": "2025-08-31T12:20:16.157965Z",
          "iopub.status.idle": "2025-08-31T12:25:10.1933Z",
          "shell.execute_reply.started": "2025-08-31T12:20:16.15795Z",
          "shell.execute_reply": "2025-08-31T12:25:10.192594Z"
        },
        "id": "yN_8d1MVwN0U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "display(train_features_df.columns)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:25:10.195132Z",
          "iopub.execute_input": "2025-08-31T12:25:10.195928Z",
          "iopub.status.idle": "2025-08-31T12:25:10.201697Z",
          "shell.execute_reply.started": "2025-08-31T12:25:10.195898Z",
          "shell.execute_reply": "2025-08-31T12:25:10.201141Z"
        },
        "id": "4amuqKN6wN0U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.MODEL EÄÄ°TÄ°MÄ° (ENHANCED ENSEMBLE)"
      ],
      "metadata": {
        "id": "P7CPLl2JwN0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 4. MODEL EÄÄ°TÄ°MÄ° (ENHANCeD ENSEMBLE)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ¤– Model eÄŸitimi baÅŸlatÄ±lÄ±yor...\")\n",
        "\n",
        "# Veriyi hazÄ±rla\n",
        "y_train = train_features_df['session_value']\n",
        "y_train_log = np.log1p(y_train)\n",
        "X_train = train_features_df.drop(['user_session', 'session_value'], axis=1)\n",
        "X_test = test_features_df.drop(['user_session'], axis=1)\n",
        "\n",
        "# SÃ¼tunlarÄ± hizala\n",
        "X_test_aligned = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
        "\n",
        "print(f\"   ğŸ“Š X_train: {X_train.shape}, X_test: {X_test_aligned.shape}\")\n",
        "\n",
        "# Train-validation split\n",
        "X_train_part, X_val, y_train_part, y_val = train_test_split(\n",
        "    X_train, y_train_log, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:25:10.202315Z",
          "iopub.execute_input": "2025-08-31T12:25:10.20258Z",
          "iopub.status.idle": "2025-08-31T12:25:10.270811Z",
          "shell.execute_reply.started": "2025-08-31T12:25:10.202557Z",
          "shell.execute_reply": "2025-08-31T12:25:10.270213Z"
        },
        "id": "Pja5uT_lwN0V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.QUICK ENSEMBLE (3 MODEL)"
      ],
      "metadata": {
        "id": "8013ubF_wN0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 5. QUICK ENSEMBLE (3 MODEL)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ¯ 3-Model Ensemble eÄŸitiliyor...\")\n",
        "\n",
        "models = {}\n",
        "predictions = {}\n",
        "\n",
        "# Kategorik sÃ¼tunlarÄ± tespit et ve dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "categorical_features = []\n",
        "cat_indices = []\n",
        "\n",
        "# X_train'in bir kopyasÄ±nÄ± al (LightGBM iÃ§in)\n",
        "X_train_lgb = X_train_part.copy()\n",
        "X_val_lgb = X_val.copy()\n",
        "\n",
        "for idx, col in enumerate(X_train.columns):\n",
        "    if X_train[col].dtype == 'category' or col.endswith('_encoded') or col == 'duration_segment':\n",
        "        categorical_features.append(col)\n",
        "        cat_indices.append(idx)\n",
        "\n",
        "        # LightGBM iÃ§in kategorik sÃ¼tunlarÄ± int'e Ã§evir\n",
        "        if X_train_lgb[col].dtype == 'object' or X_train_lgb[col].dtype == 'category':\n",
        "            # Ã–nce string'e sonra int'e Ã§evir\n",
        "            X_train_lgb[col] = X_train_lgb[col].astype(str).astype('category').cat.codes\n",
        "            X_val_lgb[col] = X_val_lgb[col].astype(str).astype('category').cat.codes\n",
        "\n",
        "print(f\"   ğŸ·ï¸ Tespit edilen kategorik sÃ¼tunlar: {categorical_features}\")\n",
        "print(f\"   ğŸ“Š Kategorik sÃ¼tun indeksleri: {cat_indices}\")\n",
        "\n",
        "# 1. CatBoost\n",
        "print(\"\\n   ğŸ± CatBoost eÄŸitiliyor...\")\n",
        "cat_params = {\n",
        "    'iterations': 2000,\n",
        "    'learning_rate': 0.05,\n",
        "    'depth': 8,\n",
        "    'l2_leaf_reg': 3.0,\n",
        "    'random_strength': 1.0,\n",
        "    'bagging_temperature': 0.2,\n",
        "    'verbose': 0,\n",
        "    'random_seed': 42,\n",
        "    'task_type': 'GPU' if 'GPU' in str(globals().get('device', '')) else 'CPU'\n",
        "}\n",
        "\n",
        "models['catboost'] = CatBoostRegressor(**cat_params)\n",
        "models['catboost'].fit(X_train_part, y_train_part,\n",
        "                      eval_set=[(X_val, y_val)],\n",
        "                      cat_features=categorical_features,\n",
        "                      early_stopping_rounds=100,\n",
        "                      verbose=0)\n",
        "\n",
        "val_pred_cat = models['catboost'].predict(X_val)\n",
        "rmse_cat = np.sqrt(mean_squared_error(y_val, val_pred_cat))\n",
        "print(f\"      âœ… Validation RMSE: {rmse_cat:.6f}\")\n",
        "\n",
        "# 2. LightGBM\n",
        "print(\"\\n   ğŸ’¡ LightGBM eÄŸitiliyor...\")\n",
        "lgb_params = {\n",
        "    'num_leaves': 100,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'min_child_samples': 20,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 0.1,\n",
        "    'random_state': 42,\n",
        "    'verbose': -1,\n",
        "    'n_estimators': 2000\n",
        "}\n",
        "\n",
        "# LightGBM iÃ§in kategorik indeksleri belirt\n",
        "models['lightgbm'] = lgb.LGBMRegressor(**lgb_params)\n",
        "models['lightgbm'].fit(\n",
        "    X_train_lgb, y_train_part,\n",
        "    eval_set=[(X_val_lgb, y_val)],\n",
        "    categorical_feature=cat_indices,  # Kategorik Ã¶zellik indekslerini belirt\n",
        "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)]\n",
        ")\n",
        "\n",
        "val_pred_lgb = models['lightgbm'].predict(X_val_lgb)\n",
        "rmse_lgb = np.sqrt(mean_squared_error(y_val, val_pred_lgb))\n",
        "print(f\"      âœ… Validation RMSE: {rmse_lgb:.6f}\")\n",
        "\n",
        "# 3. XGBoost\n",
        "print(\"\\n   ğŸš€ XGBoost eÄŸitiliyor...\")\n",
        "xgb_params = {\n",
        "    'n_estimators': 2000,\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 6,\n",
        "    'min_child_weight': 3,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 0.1,\n",
        "    'random_state': 42,\n",
        "    'tree_method': 'hist',  # Daha hÄ±zlÄ± eÄŸitim iÃ§in\n",
        "    'enable_categorical': True,  # XGBoost'ta kategorik destek\n",
        "    'early_stopping_rounds': 100  # Yeni versiyonda buraya taÅŸÄ±ndÄ±\n",
        "}\n",
        "\n",
        "# XGBoost iÃ§in de kategorik sÃ¼tunlarÄ± dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "X_train_xgb = X_train_part.copy()\n",
        "X_val_xgb = X_val.copy()\n",
        "\n",
        "for col in categorical_features:\n",
        "    if X_train_xgb[col].dtype == 'object':\n",
        "        X_train_xgb[col] = X_train_xgb[col].astype('category')\n",
        "        X_val_xgb[col] = X_val_xgb[col].astype('category')\n",
        "\n",
        "models['xgboost'] = xgb.XGBRegressor(**xgb_params)\n",
        "models['xgboost'].fit(\n",
        "    X_train_xgb, y_train_part,\n",
        "    eval_set=[(X_val_xgb, y_val)],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "val_pred_xgb = models['xgboost'].predict(X_val_xgb)\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_val, val_pred_xgb))\n",
        "print(f\"      âœ… Validation RMSE: {rmse_xgb:.6f}\")\n",
        "\n",
        "# Ensemble tahminleri - aÄŸÄ±rlÄ±klÄ± ortalama\n",
        "print(\"\\n   ğŸ”„ Ensemble tahminleri hesaplanÄ±yor...\")\n",
        "\n",
        "# Performansa gÃ¶re dinamik aÄŸÄ±rlÄ±klar\n",
        "total_inv_rmse = 1/rmse_cat + 1/rmse_lgb + 1/rmse_xgb\n",
        "weights = {\n",
        "    'catboost': (1/rmse_cat) / total_inv_rmse,\n",
        "    'lightgbm': (1/rmse_lgb) / total_inv_rmse,\n",
        "    'xgboost': (1/rmse_xgb) / total_inv_rmse\n",
        "}\n",
        "\n",
        "print(f\"\\n   ğŸ“Š Model AÄŸÄ±rlÄ±klarÄ±:\")\n",
        "print(f\"      CatBoost: {weights['catboost']:.3f}\")\n",
        "print(f\"      LightGBM: {weights['lightgbm']:.3f}\")\n",
        "print(f\"      XGBoost:  {weights['xgboost']:.3f}\")\n",
        "\n",
        "# AÄŸÄ±rlÄ±klÄ± ensemble\n",
        "ensemble_val_pred = (\n",
        "    weights['catboost'] * val_pred_cat +\n",
        "    weights['lightgbm'] * val_pred_lgb +\n",
        "    weights['xgboost'] * val_pred_xgb\n",
        ")\n",
        "\n",
        "ensemble_rmse = np.sqrt(mean_squared_error(y_val, ensemble_val_pred))\n",
        "print(f\"\\n   ğŸ¯ Ensemble Validation RMSE: {ensemble_rmse:.6f}\")\n",
        "\n",
        "# Model performans Ã¶zeti\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"   ğŸ“ˆ MODEL PERFORMANS Ã–ZETÄ°\")\n",
        "print(\"=\"*60)\n",
        "print(f\"   CatBoost RMSE:  {rmse_cat:.6f}\")\n",
        "print(f\"   LightGBM RMSE:  {rmse_lgb:.6f}\")\n",
        "print(f\"   XGBoost RMSE:   {rmse_xgb:.6f}\")\n",
        "print(f\"   Ensemble RMSE:  {ensemble_rmse:.6f}\")\n",
        "print(f\"   Ä°yileÅŸtirme:    {min(rmse_cat, rmse_lgb, rmse_xgb) - ensemble_rmse:.6f}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:25:10.271553Z",
          "iopub.execute_input": "2025-08-31T12:25:10.271774Z",
          "iopub.status.idle": "2025-08-31T12:26:04.738401Z",
          "shell.execute_reply.started": "2025-08-31T12:25:10.27175Z",
          "shell.execute_reply": "2025-08-31T12:26:04.737817Z"
        },
        "id": "dTLMA_mLwN0W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.FINAL MODEL EÄÄ°TÄ°MÄ° (FULL DATA - 2 MODEL)"
      ],
      "metadata": {
        "id": "RlawVIY3wN0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 6. FINAL MODEL EÄÄ°TÄ°MÄ° (FULL DATA - 2 MODEL)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ† Final model eÄŸitimi (full data - 2 model)...\")\n",
        "\n",
        "final_models = {}\n",
        "\n",
        "# Kategorik sÃ¼tunlarÄ± belirle\n",
        "categorical_features = []\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'category':\n",
        "        categorical_features.append(col)\n",
        "\n",
        "print(f\"ğŸ“Š Kategorik sÃ¼tunlar: {categorical_features}\")\n",
        "\n",
        "# CatBoost final\n",
        "final_models['catboost'] = CatBoostRegressor(**cat_params)\n",
        "final_models['catboost'].fit(\n",
        "    X_train,\n",
        "    y_train_log,\n",
        "    cat_features=categorical_features,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# LightGBM final - mevcut parametreleri kullan (zaten n_estimators=2000 var)\n",
        "final_models['lightgbm'] = lgb.LGBMRegressor(**lgb_params)\n",
        "final_models['lightgbm'].fit(X_train, y_train_log)\n",
        "\n",
        "print(\"âœ… Final model eÄŸitimi tamamlandÄ±!\")\n",
        "\n",
        "# Model performanslarÄ±nÄ± kontrol et\n",
        "print(\"\\nğŸ“ˆ Final model performanslarÄ±:\")\n",
        "for name, model in final_models.items():\n",
        "    train_pred = model.predict(X_train)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train_log, train_pred))\n",
        "    print(f\"{name.upper()}: Train RMSE = {train_rmse:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:26:04.738887Z",
          "iopub.execute_input": "2025-08-31T12:26:04.739072Z",
          "iopub.status.idle": "2025-08-31T12:28:02.459928Z",
          "shell.execute_reply.started": "2025-08-31T12:26:04.73905Z",
          "shell.execute_reply": "2025-08-31T12:28:02.459222Z"
        },
        "id": "2_VGgAPQwN0Y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.TAHMÄ°N VE SUBMÄ°SSÄ°ON (2 MODEL)"
      ],
      "metadata": {
        "id": "t6m97gFGwN0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 7. TAHMÄ°N VE SUBMÄ°SSÄ°ON (2 MODEL)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ”® Tahminler yapÄ±lÄ±yor...\")\n",
        "\n",
        "# Test predictions\n",
        "test_preds = {}\n",
        "for name, model in final_models.items():\n",
        "    test_preds[name] = model.predict(X_test_aligned)\n",
        "\n",
        "# Ensemble prediction (adjusted for 2 models)\n",
        "final_prediction_log = (weights['catboost'] * test_preds['catboost'] +\n",
        "                       weights['lightgbm'] * test_preds['lightgbm'])\n",
        "\n",
        "# Convert back to original scale\n",
        "final_prediction = np.expm1(final_prediction_log)\n",
        "final_prediction[final_prediction < 0] = 0\n",
        "\n",
        "# Create model predictions DataFrame\n",
        "model_predictions_df = pd.DataFrame({\n",
        "    'user_session': test_features_df['user_session'],\n",
        "    'session_value': final_prediction\n",
        "})"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:28:02.460699Z",
          "iopub.execute_input": "2025-08-31T12:28:02.461159Z",
          "iopub.status.idle": "2025-08-31T12:28:07.191078Z",
          "shell.execute_reply.started": "2025-08-31T12:28:02.461139Z",
          "shell.execute_reply": "2025-08-31T12:28:07.190478Z"
        },
        "id": "P1K1OMpjwN0Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.SUBMÄ°SSÄ°ON DOSYASI OLUÅTURMA"
      ],
      "metadata": {
        "id": "6MOWoQaNwN0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 8. SUBMÄ°SSÄ°ON DOSYASI OLUÅTURMA\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ“ Submission dosyasÄ± oluÅŸturuluyor...\")\n",
        "\n",
        "# Official template\n",
        "submission_df = test[['user_session']].drop_duplicates().copy()\n",
        "\n",
        "# Fill leaked data first\n",
        "if len(leak_map) > 0:\n",
        "    submission_df['session_value'] = submission_df['user_session'].map(leak_map)\n",
        "    leaked_count = len(submission_df) - submission_df['session_value'].isnull().sum()\n",
        "    print(f\"   ğŸ” {leaked_count} leaked prediction eklendi\")\n",
        "else:\n",
        "    submission_df['session_value'] = np.nan\n",
        "    leaked_count = 0\n",
        "\n",
        "# Fill remaining with model predictions\n",
        "model_predictions_map = model_predictions_df.set_index('user_session')['session_value']\n",
        "submission_df['session_value'] = submission_df['session_value'].fillna(\n",
        "    submission_df['user_session'].map(model_predictions_map)\n",
        ")\n",
        "\n",
        "filled_by_model = len(submission_df) - submission_df['session_value'].isnull().sum() - leaked_count\n",
        "print(f\"   ğŸ¤– {filled_by_model} model prediction eklendi\")\n",
        "\n",
        "# Final check\n",
        "if submission_df['session_value'].isnull().sum() > 0:\n",
        "    print(\"   âš ï¸ BoÅŸ deÄŸerler ortalama ile dolduruluyor...\")\n",
        "    submission_df['session_value'].fillna(y_train.mean(), inplace=True)\n",
        "\n",
        "# Save submission\n",
        "submission_path = '/content/improved_submission.csv'\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"ğŸ‰ BAÅARILI! Submission dosyasÄ± hazÄ±r: {submission_path}\")\n",
        "print(f\"ğŸ“Š Toplam prediction: {len(submission_df)}\")\n",
        "print(f\"ğŸ“ˆ Ensemble validation RMSE: {ensemble_rmse:.6f}\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ Ä°yileÅŸtirilmiÅŸ model pipeline tamamlandÄ±!\")\n",
        "print(\"=\"*60)# 1.VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:28:07.191738Z",
          "iopub.execute_input": "2025-08-31T12:28:07.191918Z",
          "iopub.status.idle": "2025-08-31T12:28:07.285032Z",
          "shell.execute_reply.started": "2025-08-31T12:28:07.191903Z",
          "shell.execute_reply": "2025-08-31T12:28:07.284499Z"
        },
        "id": "P3lW4ngjwN0a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N)"
      ],
      "metadata": {
        "id": "teQw4dB9wN0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 1. VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ”„ Adversarial validation iÃ§in veri hazÄ±rlanÄ±yor...\")\n",
        "\n",
        "# Train ve test veri setlerine kaynak etiketi ekle\n",
        "X_train['source'] = 0  # 0 for train\n",
        "X_test_aligned['source'] = 1 # 1 for test\n",
        "\n",
        "# Train ve test Ã¶zelliklerini birleÅŸtir\n",
        "# Kategorik sÃ¼tunlarÄ± birleÅŸtirmeden Ã¶nce object'e Ã§evir\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'category':\n",
        "        X_train[col] = X_train[col].astype(object)\n",
        "        X_test_aligned[col] = X_test_aligned[col].astype(object)\n",
        "\n",
        "\n",
        "adversarial_data = pd.concat([X_train, X_test_aligned], ignore_index=True)\n",
        "\n",
        "# Hedef deÄŸiÅŸkeni (source) ayÄ±r\n",
        "adversarial_target = adversarial_data['source']\n",
        "adversarial_features = adversarial_data.drop('source', axis=1)\n",
        "\n",
        "print(f\"   BirleÅŸtirilmiÅŸ veri boyutu: {adversarial_data.shape}\")\n",
        "print(\"âœ… Veri hazÄ±rlÄ±ÄŸÄ± tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:37:26.351428Z",
          "iopub.execute_input": "2025-08-31T12:37:26.352107Z",
          "iopub.status.idle": "2025-08-31T12:37:26.397087Z",
          "shell.execute_reply.started": "2025-08-31T12:37:26.352084Z",
          "shell.execute_reply": "2025-08-31T12:37:26.396219Z"
        },
        "id": "fH2gWjFcwN0b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (LightGBM Ä°LE)"
      ],
      "metadata": {
        "id": "YO3F1egKwN0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 2. ADVERSARIAL MODEL EÄÄ°TÄ°MÄ°\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\n adversarial model eÄŸitiliyor...\")\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Adversarial model iÃ§in LightGBM sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±\n",
        "lgb_adv_params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'n_estimators': 1000,\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': -1,\n",
        "    'seed': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbose': -1,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'subsample': 0.8,\n",
        "    'reg_alpha': 0.1,\n",
        "    'reg_lambda': 0.1,\n",
        "}\n",
        "\n",
        "# Kategorik Ã¶zellikleri tekrar belirle (birleÅŸtirilmiÅŸ veri Ã¼zerinde)\n",
        "# BirleÅŸtirmeden Ã¶nce object'e Ã§evrildikleri iÃ§in burada tekrar category yapalÄ±m\n",
        "for col in adversarial_features.columns:\n",
        "    if adversarial_features[col].dtype == 'object':\n",
        "        adversarial_features[col] = adversarial_features[col].astype('category')\n",
        "\n",
        "categorical_features_adv = [col for col in adversarial_features.columns if adversarial_features[col].dtype == 'category']\n",
        "\n",
        "print(f\"   Adversarial model iÃ§in kategorik sÃ¼tunlar: {categorical_features_adv}\")\n",
        "\n",
        "\n",
        "# Ã‡apraz doÄŸrulama ile eÄŸit\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_preds = np.zeros(adversarial_data.shape[0])\n",
        "feature_importances = pd.DataFrame(index=adversarial_features.columns)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(adversarial_features, adversarial_target)):\n",
        "    print(f\"\\n   Fold {fold+1}/5\")\n",
        "    X_train_fold, X_val_fold = adversarial_features.iloc[train_idx], adversarial_features.iloc[val_idx]\n",
        "    y_train_fold, y_val_fold = adversarial_target.iloc[train_idx], adversarial_target.iloc[val_idx]\n",
        "\n",
        "    model = lgb.LGBMClassifier(**lgb_adv_params)\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold,\n",
        "              eval_set=[(X_val_fold, y_val_fold)],\n",
        "              eval_metric='auc',\n",
        "              callbacks=[lgb.early_stopping(100, verbose=False)],\n",
        "              categorical_feature=categorical_features_adv)\n",
        "\n",
        "    oof_preds[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n",
        "    feature_importances[f'fold_{fold+1}'] = model.feature_importances_\n",
        "\n",
        "# OOF tahminleri Ã¼zerinden AUC hesapla\n",
        "overall_auc = roc_auc_score(adversarial_target, oof_preds)\n",
        "\n",
        "print(f\"\\nâœ… Adversarial model eÄŸitimi tamamlandÄ±!\")\n",
        "print(f\"   Overall Adversarial AUC: {overall_auc:.6f}\")\n",
        "\n",
        "# Feature importances ortalamasÄ±nÄ± hesapla\n",
        "feature_importances['average'] = feature_importances.mean(axis=1)\n",
        "feature_importances = feature_importances.sort_values('average', ascending=False)\n",
        "\n",
        "print(\"\\n   Ã–nemli Ã–zellikler (En YÃ¼ksekten En DÃ¼ÅŸÃ¼ÄŸe):\")\n",
        "print(feature_importances[['average']].head(20)) # En Ã¶nemli 20 Ã¶zelliÄŸi gÃ¶ster"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:37:29.07094Z",
          "iopub.execute_input": "2025-08-31T12:37:29.071214Z",
          "iopub.status.idle": "2025-08-31T12:37:45.46974Z",
          "shell.execute_reply.started": "2025-08-31T12:37:29.071193Z",
          "shell.execute_reply": "2025-08-31T12:37:45.46902Z"
        },
        "id": "wTImE-wUwN0d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (CATBOOST Ä°LE)"
      ],
      "metadata": {
        "id": "5aeAPdvVwN0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 2. ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (CATBOOST Ä°LE - YENÄ° DENEME)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\n adversarial model eÄŸitiliyor (CatBoost)...\")\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Adversarial model iÃ§in CatBoost sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±\n",
        "cat_adv_params = {\n",
        "    'objective': 'Logloss',  # Binary classification objective\n",
        "    'eval_metric': 'AUC',\n",
        "    'iterations': 1000,\n",
        "    'learning_rate': 0.05,\n",
        "    'depth': 6,\n",
        "    'random_seed': 42,\n",
        "    'verbose': 0, # Daha fazla bilgi iÃ§in 100 yapabilirsiniz\n",
        "    'task_type': 'GPU' if 'GPU' in str(globals().get('device', '')) else 'CPU',\n",
        "    'early_stopping_rounds': 100\n",
        "}\n",
        "\n",
        "# Kategorik Ã¶zellikleri belirle\n",
        "# CatBoost string/object tÃ¼rÃ¼ndeki kategoriklere doÄŸrudan destek verir.\n",
        "# Ã–nceki adÄ±mda object'e Ã§evirmiÅŸtik, CatBoost bunu kabul eder.\n",
        "categorical_features_adv = [col for col in adversarial_features.columns if adversarial_features[col].dtype == 'object' or adversarial_features[col].dtype == 'category']\n",
        "\n",
        "print(f\"   Adversarial model iÃ§in kategorik sÃ¼tunlar: {categorical_features_adv}\")\n",
        "\n",
        "\n",
        "# Ã‡apraz doÄŸrulama ile eÄŸit\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_preds_catboost = np.zeros(adversarial_data.shape[0])\n",
        "feature_importances_catboost = pd.DataFrame(index=adversarial_features.columns)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(adversarial_features, adversarial_target)):\n",
        "    print(f\"\\n   Fold {fold+1}/5\")\n",
        "    X_train_fold, X_val_fold = adversarial_features.iloc[train_idx], adversarial_features.iloc[val_idx]\n",
        "    y_train_fold, y_val_fold = adversarial_target.iloc[train_idx], adversarial_target.iloc[val_idx]\n",
        "\n",
        "    model = CatBoostClassifier(**cat_adv_params)\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold,\n",
        "              eval_set=[(X_val_fold, y_val_fold)],\n",
        "              cat_features=categorical_features_adv,\n",
        "              early_stopping_rounds=cat_adv_params['early_stopping_rounds'],\n",
        "              verbose=cat_adv_params['verbose'])\n",
        "\n",
        "    oof_preds_catboost[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n",
        "    feature_importances_catboost[f'fold_{fold+1}'] = model.get_feature_importance() # CatBoost feature importance alma\n",
        "\n",
        "# OOF tahminleri Ã¼zerinden AUC hesapla\n",
        "overall_auc_catboost = roc_auc_score(adversarial_target, oof_preds_catboost)\n",
        "\n",
        "print(f\"\\nâœ… Adversarial model eÄŸitimi tamamlandÄ±!\")\n",
        "print(f\"   Overall Adversarial AUC (CatBoost): {overall_auc_catboost:.6f}\")\n",
        "\n",
        "# Feature importances ortalamasÄ±nÄ± hesapla\n",
        "feature_importances_catboost['average'] = feature_importances_catboost.mean(axis=1)\n",
        "feature_importances_catboost = feature_importances_catboost.sort_values('average', ascending=False)\n",
        "\n",
        "print(\"\\n   Ã–nemli Ã–zellikler (En YÃ¼ksekten En DÃ¼ÅŸÃ¼ÄŸe - CatBoost):\")\n",
        "print(feature_importances_catboost[['average']].head(20)) # En Ã¶nemli 20 Ã¶zelliÄŸi gÃ¶ster"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:37:58.318704Z",
          "iopub.execute_input": "2025-08-31T12:37:58.318994Z",
          "iopub.status.idle": "2025-08-31T12:41:16.511828Z",
          "shell.execute_reply.started": "2025-08-31T12:37:58.318972Z",
          "shell.execute_reply": "2025-08-31T12:41:16.511088Z"
        },
        "id": "T3ums0rfwN0f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Ã–NEMLÄ° Ã–ZELLÄ°KLERÄ°N DAÄILIMLARINI GÃ–RSELLEÅTÄ°RME\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "03urtolBwN0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 3. Ã–NEMLÄ° Ã–ZELLÄ°KLERÄ°N DAÄILIMLARINI GÃ–RSELLEÅTÄ°RME\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ“Š En Ã¶nemli Ã¶zelliklerin daÄŸÄ±lÄ±mlarÄ± gÃ¶rselleÅŸtiriliyor...\")\n",
        "\n",
        "# Adversarial modelin en Ã¶nemli bulduÄŸu Ã¶zellikler (ilk 10)\n",
        "top_features = feature_importances_catboost['average'].head(10).index.tolist()\n",
        "print(f\"   GÃ¶rselleÅŸtirilecek Ã¶zellikler: {top_features}\")\n",
        "\n",
        "# Adversarial data frame'ini tekrar train ve test olarak ayÄ±r\n",
        "adversarial_data['source'] = adversarial_target # Add source back for splitting\n",
        "train_adversarial = adversarial_data[adversarial_data['source'] == 0].drop('source', axis=1)\n",
        "test_adversarial = adversarial_data[adversarial_data['source'] == 1].drop('source', axis=1)\n",
        "\n",
        "\n",
        "# DaÄŸÄ±lÄ±mlarÄ± gÃ¶rselleÅŸtir\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, feature in enumerate(top_features):\n",
        "    plt.subplot(4, 3, i + 1) # Adjust grid size based on number of features\n",
        "    sns.histplot(data=train_adversarial, x=feature, color='skyblue', label='Train', kde=True, stat='density', common_norm=False)\n",
        "    sns.histplot(data=test_adversarial, x=feature, color='lightcoral', label='Test', kde=True, stat='density', common_norm=False)\n",
        "    plt.title(f'Distribution of {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… GÃ¶rselleÅŸtirmeler tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:41:16.513015Z",
          "iopub.execute_input": "2025-08-31T12:41:16.513283Z",
          "iopub.status.idle": "2025-08-31T12:49:17.236405Z",
          "shell.execute_reply.started": "2025-08-31T12:41:16.513264Z",
          "shell.execute_reply": "2025-08-31T12:49:17.235682Z"
        },
        "id": "UFfpJnNLwN0g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.ADVERSARIAL MODEL FEATURE IMPORTANCE GÃ–RSELLEÅTÄ°RME"
      ],
      "metadata": {
        "id": "2r-tW5c7wN0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 4. ADVERSARIAL MODEL FEATURE IMPORTANCE GÃ–RSELLEÅTÄ°RME\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ“Š Adversarial model feature importance gÃ¶rselleÅŸtiriliyor...\")\n",
        "\n",
        "# CatBoost modelinden elde edilen ortalama feature importance deÄŸerleri\n",
        "feature_importance = feature_importances_catboost['average']\n",
        "\n",
        "# Feature importance deÄŸerlerini sÄ±rala\n",
        "sorted_idx = feature_importance.sort_values(ascending=False).index\n",
        "sorted_importance = feature_importance[sorted_idx]\n",
        "\n",
        "# GÃ¶rselleÅŸtirmeyi yap\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(sorted_idx)), sorted_importance, align='center')\n",
        "plt.yticks(range(len(sorted_idx)), sorted_idx)\n",
        "plt.xlabel('Average Feature Importance (Adversarial)')\n",
        "plt.title('Adversarial Model Feature Importance')\n",
        "plt.gca().invert_yaxis() # En Ã¶nemli Ã¶zelliÄŸi en Ã¼ste almak iÃ§in y eksenini ters Ã§evir\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Feature importance gÃ¶rselleÅŸtirme tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:49:17.23724Z",
          "iopub.execute_input": "2025-08-31T12:49:17.23747Z",
          "iopub.status.idle": "2025-08-31T12:49:17.791464Z",
          "shell.execute_reply.started": "2025-08-31T12:49:17.237429Z",
          "shell.execute_reply": "2025-08-31T12:49:17.790731Z"
        },
        "id": "GETRwFkawN0g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N) - user_id_encoded Ã§Ä±karÄ±ldÄ±"
      ],
      "metadata": {
        "id": "UIe3OgNAwN0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 1. VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N) - user_id_encoded Ã§Ä±karÄ±ldÄ±\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ”„ Adversarial validation iÃ§in veri hazÄ±rlanÄ±yor (user_id_encoded Ã§Ä±karÄ±ldÄ±)...\")\n",
        "\n",
        "# Train ve test veri setlerine kaynak etiketi ekle\n",
        "X_train_modified = X_train.copy() # Kopya al\n",
        "X_test_aligned_modified = X_test_aligned.copy() # Kopya al\n",
        "\n",
        "# user_id_encoded sÃ¼tununu Ã§Ä±kar\n",
        "if 'user_id_encoded' in X_train_modified.columns:\n",
        "    X_train_modified = X_train_modified.drop('user_id_encoded', axis=1)\n",
        "    print(\"   'user_id_encoded' train Ã¶zelliklerinden Ã§Ä±karÄ±ldÄ±.\")\n",
        "if 'user_id_encoded' in X_test_aligned_modified.columns:\n",
        "    X_test_aligned_modified = X_test_aligned_modified.drop('user_id_encoded', axis=1)\n",
        "    print(\"   'user_id_encoded' test Ã¶zelliklerinden Ã§Ä±karÄ±ldÄ±.\")\n",
        "\n",
        "\n",
        "X_train_modified['source'] = 0  # 0 for train\n",
        "X_test_aligned_modified['source'] = 1 # 1 for test\n",
        "\n",
        "# Train ve test Ã¶zelliklerini birleÅŸtir\n",
        "# Kategorik sÃ¼tunlarÄ± birleÅŸtirmeden Ã¶nce object'e Ã§evir\n",
        "for col in X_train_modified.columns:\n",
        "    if X_train_modified[col].dtype == 'category':\n",
        "        X_train_modified[col] = X_train_modified[col].astype(object)\n",
        "        X_test_aligned_modified[col] = X_test_aligned_modified[col].astype(object)\n",
        "\n",
        "\n",
        "adversarial_data_no_userid = pd.concat([X_train_modified, X_test_aligned_modified], ignore_index=True)\n",
        "\n",
        "# Hedef deÄŸiÅŸkeni (source) ayÄ±r\n",
        "adversarial_target_no_userid = adversarial_data_no_userid['source']\n",
        "adversarial_features_no_userid = adversarial_data_no_userid.drop('source', axis=1)\n",
        "\n",
        "print(f\"   BirleÅŸtirilmiÅŸ veri boyutu (user_id_encoded olmadan): {adversarial_data_no_userid.shape}\")\n",
        "print(\"âœ… Veri hazÄ±rlÄ±ÄŸÄ± tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:49:17.793468Z",
          "iopub.execute_input": "2025-08-31T12:49:17.794069Z",
          "iopub.status.idle": "2025-08-31T12:49:17.847291Z",
          "shell.execute_reply.started": "2025-08-31T12:49:17.794044Z",
          "shell.execute_reply": "2025-08-31T12:49:17.846688Z"
        },
        "id": "PLlofTFJwN0g"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (CATBOOST Ä°LE - user_id_encoded olmadan)"
      ],
      "metadata": {
        "id": "2AbvY78kwN0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 2. ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (CATBOOST Ä°LE - user_id_encoded olmadan)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\n adversarial model eÄŸitiliyor (CatBoost - user_id_encoded olmadan)...\")\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Adversarial model iÃ§in CatBoost sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± - Parametreler aynÄ± kalabilir\n",
        "cat_adv_params_no_userid = {\n",
        "    'objective': 'Logloss',  # Binary classification objective\n",
        "    'eval_metric': 'AUC',\n",
        "    'iterations': 1000,\n",
        "    'learning_rate': 0.05,\n",
        "    'depth': 6,\n",
        "    'random_seed': 42,\n",
        "    'verbose': 0, # Daha fazla bilgi iÃ§in 100 yapabilirsiniz\n",
        "    'task_type': 'GPU' if 'GPU' in str(globals().get('device', '')) else 'CPU',\n",
        "    'early_stopping_rounds': 100\n",
        "}\n",
        "\n",
        "# Kategorik Ã¶zellikleri belirle (user_id_encoded olmadan)\n",
        "# CatBoost string/object tÃ¼rÃ¼ndeki kategoriklere doÄŸrudan destek verir.\n",
        "categorical_features_adv_no_userid = [col for col in adversarial_features_no_userid.columns if adversarial_features_no_userid[col].dtype == 'object' or adversarial_features_no_userid[col].dtype == 'category']\n",
        "\n",
        "print(f\"   Adversarial model iÃ§in kategorik sÃ¼tunlar (user_id_encoded olmadan): {categorical_features_adv_no_userid}\")\n",
        "\n",
        "\n",
        "# Ã‡apraz doÄŸrulama ile eÄŸit\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_preds_catboost_no_userid = np.zeros(adversarial_data_no_userid.shape[0])\n",
        "feature_importances_catboost_no_userid = pd.DataFrame(index=adversarial_features_no_userid.columns)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(adversarial_features_no_userid, adversarial_target_no_userid)):\n",
        "    print(f\"\\n   Fold {fold+1}/5\")\n",
        "    X_train_fold, X_val_fold = adversarial_features_no_userid.iloc[train_idx], adversarial_features_no_userid.iloc[val_idx]\n",
        "    y_train_fold, y_val_fold = adversarial_target_no_userid.iloc[train_idx], adversarial_target_no_userid.iloc[val_idx]\n",
        "\n",
        "    model = CatBoostClassifier(**cat_adv_params_no_userid)\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold,\n",
        "              eval_set=[(X_val_fold, y_val_fold)],\n",
        "              cat_features=categorical_features_adv_no_userid,\n",
        "              early_stopping_rounds=cat_adv_params_no_userid['early_stopping_rounds'],\n",
        "              verbose=cat_adv_params_no_userid['verbose'])\n",
        "\n",
        "    oof_preds_catboost_no_userid[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n",
        "    feature_importances_catboost_no_userid[f'fold_{fold+1}'] = model.get_feature_importance() # CatBoost feature importance alma\n",
        "\n",
        "# OOF tahminleri Ã¼zerinden AUC hesapla\n",
        "overall_auc_catboost_no_userid = roc_auc_score(adversarial_target_no_userid, oof_preds_catboost_no_userid)\n",
        "\n",
        "print(f\"\\nâœ… Adversarial model eÄŸitimi tamamlandÄ±!\")\n",
        "print(f\"   Overall Adversarial AUC (CatBoost - user_id_encoded olmadan): {overall_auc_catboost_no_userid:.6f}\")\n",
        "\n",
        "# Feature importances ortalamasÄ±nÄ± hesapla\n",
        "feature_importances_catboost_no_userid['average'] = feature_importances_catboost_no_userid.mean(axis=1)\n",
        "feature_importances_catboost_no_userid = feature_importances_catboost_no_userid.sort_values('average', ascending=False)\n",
        "\n",
        "print(\"\\n   Ã–nemli Ã–zellikler (En YÃ¼ksekten En DÃ¼ÅŸÃ¼ÄŸe - CatBoost - user_id_encoded olmadan):\")\n",
        "print(feature_importances_catboost_no_userid[['average']].head(20)) # En Ã¶nemli 20 Ã¶zelliÄŸi gÃ¶ster"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:49:17.847985Z",
          "iopub.execute_input": "2025-08-31T12:49:17.848229Z",
          "iopub.status.idle": "2025-08-31T12:51:06.419784Z",
          "shell.execute_reply.started": "2025-08-31T12:49:17.848205Z",
          "shell.execute_reply": "2025-08-31T12:51:06.419081Z"
        },
        "id": "Tz7hdPaQwN0h"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.ADVERSARIAL MODEL FEATURE IMPORTANCE GÃ–RSELLEÅTÄ°RME (USER_ID_ENCODED OLMADAN)"
      ],
      "metadata": {
        "id": "kOWmLC8dwN0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 4. ADVERSARIAL MODEL FEATURE IMPORTANCE GÃ–RSELLEÅTÄ°RME (USER_ID_ENCODED OLMADAN)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ“Š Adversarial model feature importance gÃ¶rselleÅŸtiriliyor (user_id_encoded olmadan)...\")\n",
        "\n",
        "# CatBoost modelinden elde edilen ortalama feature importance deÄŸerleri (user_id_encoded olmadan)\n",
        "feature_importance_no_userid = feature_importances_catboost_no_userid['average']\n",
        "\n",
        "# Feature importance deÄŸerlerini sÄ±rala\n",
        "sorted_idx_no_userid = feature_importance_no_userid.sort_values(ascending=False).index\n",
        "sorted_importance_no_userid = feature_importance_no_userid[sorted_idx_no_userid]\n",
        "\n",
        "# GÃ¶rselleÅŸtirmeyi yap\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(sorted_idx_no_userid)), sorted_importance_no_userid, align='center')\n",
        "plt.yticks(range(len(sorted_idx_no_userid)), sorted_idx_no_userid)\n",
        "plt.xlabel('Average Feature Importance (Adversarial - No User ID)')\n",
        "plt.title('Adversarial Model Feature Importance (No User ID)')\n",
        "plt.gca().invert_yaxis() # En Ã¶nemli Ã¶zelliÄŸi en Ã¼ste almak iÃ§in y eksenini ters Ã§evir\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Feature importance gÃ¶rselleÅŸtirme tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:51:06.420507Z",
          "iopub.execute_input": "2025-08-31T12:51:06.420704Z",
          "iopub.status.idle": "2025-08-31T12:51:06.965587Z",
          "shell.execute_reply.started": "2025-08-31T12:51:06.420689Z",
          "shell.execute_reply": "2025-08-31T12:51:06.964799Z"
        },
        "id": "DIpxvMiBwN0i"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N) - user_id_encoded ve day_cos Ã§Ä±karÄ±ldÄ±"
      ],
      "metadata": {
        "id": "ekprXq-DwN0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 1. VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N) - user_id_encoded ve day_cos Ã§Ä±karÄ±ldÄ±\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ”„ Adversarial validation iÃ§in veri hazÄ±rlanÄ±yor (user_id_encoded ve day_cos Ã§Ä±karÄ±ldÄ±)...\")\n",
        "\n",
        "# Train ve test veri setlerine kaynak etiketi ekle\n",
        "X_train_modified_2 = X_train.copy() # Kopya al\n",
        "X_test_aligned_modified_2 = X_test_aligned.copy() # Kopya al\n",
        "\n",
        "# user_id_encoded ve day_cos sÃ¼tunlarÄ±nÄ± Ã§Ä±kar\n",
        "cols_to_drop = ['user_id_encoded', 'day_cos']\n",
        "for col in cols_to_drop:\n",
        "    if col in X_train_modified_2.columns:\n",
        "        X_train_modified_2 = X_train_modified_2.drop(col, axis=1)\n",
        "        print(f\"   '{col}' train Ã¶zelliklerinden Ã§Ä±karÄ±ldÄ±.\")\n",
        "    if col in X_test_aligned_modified_2.columns:\n",
        "        X_test_aligned_modified_2 = X_test_aligned_modified_2.drop(col, axis=1)\n",
        "        print(f\"   '{col}' test Ã¶zelliklerinden Ã§Ä±karÄ±ldÄ±.\")\n",
        "\n",
        "\n",
        "X_train_modified_2['source'] = 0  # 0 for train\n",
        "X_test_aligned_modified_2['source'] = 1 # 1 for test\n",
        "\n",
        "# Train ve test Ã¶zelliklerini birleÅŸtir\n",
        "# Kategorik sÃ¼tunlarÄ± birleÅŸtirmeden Ã¶nce object'e Ã§evir\n",
        "for col in X_train_modified_2.columns:\n",
        "    if X_train_modified_2[col].dtype == 'category':\n",
        "        X_train_modified_2[col] = X_train_modified_2[col].astype(object)\n",
        "        X_test_aligned_modified_2[col] = X_test_aligned_modified_2[col].astype(object)\n",
        "\n",
        "\n",
        "adversarial_data_no_userid_daycos = pd.concat([X_train_modified_2, X_test_aligned_modified_2], ignore_index=True)\n",
        "\n",
        "# Hedef deÄŸiÅŸkeni (source) ayÄ±r\n",
        "adversarial_target_no_userid_daycos = adversarial_data_no_userid_daycos['source']\n",
        "adversarial_features_no_userid_daycos = adversarial_data_no_userid_daycos.drop('source', axis=1)\n",
        "\n",
        "print(f\"   BirleÅŸtirilmiÅŸ veri boyutu (user_id_encoded ve day_cos olmadan): {adversarial_data_no_userid_daycos.shape}\")\n",
        "print(\"âœ… Veri hazÄ±rlÄ±ÄŸÄ± tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:51:06.966407Z",
          "iopub.execute_input": "2025-08-31T12:51:06.966669Z",
          "iopub.status.idle": "2025-08-31T12:51:07.031967Z",
          "shell.execute_reply.started": "2025-08-31T12:51:06.966642Z",
          "shell.execute_reply": "2025-08-31T12:51:07.031191Z"
        },
        "id": "c8K4VVqgwN0j"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (CATBOOST Ä°LE - user_id_encoded ve day_cos olmadan)"
      ],
      "metadata": {
        "id": "ctkAjfM7wN0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 2. ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (CATBOOST Ä°LE - user_id_encoded ve day_cos olmadan)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\n adversarial model eÄŸitiliyor (CatBoost - user_id_encoded ve day_cos olmadan)...\")\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Adversarial model iÃ§in CatBoost sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± - Parametreler aynÄ± kalabilir\n",
        "cat_adv_params_no_userid_daycos = {\n",
        "    'objective': 'Logloss',  # Binary classification objective\n",
        "    'eval_metric': 'AUC',\n",
        "    'iterations': 1000,\n",
        "    'learning_rate': 0.05,\n",
        "    'depth': 6,\n",
        "    'random_seed': 42,\n",
        "    'verbose': 0, # Daha fazla bilgi iÃ§in 100 yapabilirsiniz\n",
        "    'task_type': 'GPU' if 'GPU' in str(globals().get('device', '')) else 'CPU',\n",
        "    'early_stopping_rounds': 100\n",
        "}\n",
        "\n",
        "# Kategorik Ã¶zellikleri belirle (user_id_encoded ve day_cos olmadan)\n",
        "# CatBoost string/object tÃ¼rÃ¼ndeki kategoriklere doÄŸrudan destek verir.\n",
        "categorical_features_adv_no_userid_daycos = [col for col in adversarial_features_no_userid_daycos.columns if adversarial_features_no_userid_daycos[col].dtype == 'object' or adversarial_features_no_userid_daycos[col].dtype == 'category']\n",
        "\n",
        "print(f\"   Adversarial model iÃ§in kategorik sÃ¼tunlar (user_id_encoded ve day_cos olmadan): {categorical_features_adv_no_userid_daycos}\")\n",
        "\n",
        "\n",
        "# Ã‡apraz doÄŸrulama ile eÄŸit\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_preds_catboost_no_userid_daycos = np.zeros(adversarial_data_no_userid_daycos.shape[0])\n",
        "feature_importances_catboost_no_userid_daycos = pd.DataFrame(index=adversarial_features_no_userid_daycos.columns)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(adversarial_features_no_userid_daycos, adversarial_target_no_userid_daycos)):\n",
        "    print(f\"\\n   Fold {fold+1}/5\")\n",
        "    X_train_fold, X_val_fold = adversarial_features_no_userid_daycos.iloc[train_idx], adversarial_features_no_userid_daycos.iloc[val_idx]\n",
        "    y_train_fold, y_val_fold = adversarial_target_no_userid_daycos.iloc[train_idx], adversarial_target_no_userid_daycos.iloc[val_idx]\n",
        "\n",
        "    model = CatBoostClassifier(**cat_adv_params_no_userid_daycos)\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold,\n",
        "              eval_set=[(X_val_fold, y_val_fold)],\n",
        "              cat_features=categorical_features_adv_no_userid_daycos,\n",
        "              early_stopping_rounds=cat_adv_params_no_userid_daycos['early_stopping_rounds'],\n",
        "              verbose=cat_adv_params_no_userid_daycos['verbose'])\n",
        "\n",
        "    oof_preds_catboost_no_userid_daycos[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n",
        "    feature_importances_catboost_no_userid_daycos[f'fold_{fold+1}'] = model.get_feature_importance() # CatBoost feature importance alma\n",
        "\n",
        "# OOF tahminleri Ã¼zerinden AUC hesapla\n",
        "overall_auc_catboost_no_userid_daycos = roc_auc_score(adversarial_target_no_userid_daycos, oof_preds_catboost_no_userid_daycos)\n",
        "\n",
        "print(f\"\\nâœ… Adversarial model eÄŸitimi tamamlandÄ±!\")\n",
        "print(f\"   Overall Adversarial AUC (CatBoost - user_id_encoded ve day_cos olmadan): {overall_auc_catboost_no_userid_daycos:.6f}\")\n",
        "\n",
        "# Feature importances ortalamasÄ±nÄ± hesapla\n",
        "feature_importances_catboost_no_userid_daycos['average'] = feature_importances_catboost_no_userid_daycos.mean(axis=1)\n",
        "feature_importances_catboost_no_userid_daycos = feature_importances_catboost_no_userid_daycos.sort_values('average', ascending=False)\n",
        "\n",
        "print(\"\\n   Ã–nemli Ã–zellikler (En YÃ¼ksekten En DÃ¼ÅŸÃ¼ÄŸe - CatBoost - user_id_encoded ve day_cos olmadan):\")\n",
        "print(feature_importances_catboost_no_userid_daycos[['average']].head(20)) # En Ã¶nemli 20 Ã¶zelliÄŸi gÃ¶ster"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:51:07.0329Z",
          "iopub.execute_input": "2025-08-31T12:51:07.033128Z",
          "iopub.status.idle": "2025-08-31T12:52:39.408094Z",
          "shell.execute_reply.started": "2025-08-31T12:51:07.033104Z",
          "shell.execute_reply": "2025-08-31T12:52:39.407331Z"
        },
        "id": "x5mJ4r1_wN0k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N) - user_id_encoded, day_cos, day_of_week ve day_sin Ã§Ä±karÄ±ldÄ±"
      ],
      "metadata": {
        "id": "5UbUcBkDwN0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 1. VERÄ° HAZIRLIÄI (ADVERSARIAL VALIDATION Ä°Ã‡Ä°N) - user_id_encoded, day_cos, day_of_week ve day_sin Ã§Ä±karÄ±ldÄ±\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ”„ Adversarial validation iÃ§in veri hazÄ±rlanÄ±yor (user_id_encoded, day_cos, day_of_week ve day_sin Ã§Ä±karÄ±ldÄ±)...\")\n",
        "\n",
        "# Train ve test veri setlerine kaynak etiketi ekle\n",
        "X_train_modified_3 = X_train.copy() # Kopya al\n",
        "X_test_aligned_modified_3 = X_test_aligned.copy() # Kopya al\n",
        "\n",
        "# user_id_encoded, day_cos, day_of_week ve day_sin sÃ¼tunlarÄ±nÄ± Ã§Ä±kar\n",
        "cols_to_drop = ['user_id_encoded', 'day_cos', 'day_of_week', 'day_sin']\n",
        "for col in cols_to_drop:\n",
        "    if col in X_train_modified_3.columns:\n",
        "        X_train_modified_3 = X_train_modified_3.drop(col, axis=1)\n",
        "        print(f\"   '{col}' train Ã¶zelliklerinden Ã§Ä±karÄ±ldÄ±.\")\n",
        "    if col in X_test_aligned_modified_3.columns:\n",
        "        X_test_aligned_modified_3 = X_test_aligned_modified_3.drop(col, axis=1)\n",
        "        print(f\"   '{col}' test Ã¶zelliklerinden Ã§Ä±karÄ±ldÄ±.\")\n",
        "\n",
        "\n",
        "X_train_modified_3['source'] = 0  # 0 for train\n",
        "X_test_aligned_modified_3['source'] = 1 # 1 for test\n",
        "\n",
        "# Train ve test Ã¶zelliklerini birleÅŸtir\n",
        "# Kategorik sÃ¼tunlarÄ± birleÅŸtirmeden Ã¶nce object'e Ã§evir\n",
        "for col in X_train_modified_3.columns:\n",
        "    if X_train_modified_3[col].dtype == 'category':\n",
        "        X_train_modified_3[col] = X_train_modified_3[col].astype(object)\n",
        "        X_test_aligned_modified_3[col] = X_test_aligned_modified_3[col].astype(object)\n",
        "\n",
        "\n",
        "adversarial_data_no_userid_daycos_dayofweek_daysin = pd.concat([X_train_modified_3, X_test_aligned_modified_3], ignore_index=True)\n",
        "\n",
        "# Hedef deÄŸiÅŸkeni (source) ayÄ±r\n",
        "adversarial_target_no_userid_daycos_dayofweek_daysin = adversarial_data_no_userid_daycos_dayofweek_daysin['source']\n",
        "adversarial_features_no_userid_daycos_dayofweek_daysin = adversarial_data_no_userid_daycos_dayofweek_daysin.drop('source', axis=1)\n",
        "\n",
        "print(f\"   BirleÅŸtirilmiÅŸ veri boyutu (user_id_encoded, day_cos, day_of_week ve day_sin olmadan): {adversarial_data_no_userid_daycos_dayofweek_daysin.shape}\")\n",
        "print(\"âœ… Veri hazÄ±rlÄ±ÄŸÄ± tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:52:39.408942Z",
          "iopub.execute_input": "2025-08-31T12:52:39.40917Z",
          "iopub.status.idle": "2025-08-31T12:52:39.506194Z",
          "shell.execute_reply.started": "2025-08-31T12:52:39.409153Z",
          "shell.execute_reply": "2025-08-31T12:52:39.505479Z"
        },
        "id": "nm-ozuYgwN0k"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (CATBOOST Ä°LE - user_id_encoded, day_cos, day_of_week ve day_sin olmadan)"
      ],
      "metadata": {
        "id": "hK-5JdzTwN0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 2. ADVERSARIAL MODEL EÄÄ°TÄ°MÄ° (CATBOOST Ä°LE - user_id_encoded, day_cos, day_of_week ve day_sin olmadan)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\n adversarial model eÄŸitiliyor (CatBoost - user_id_encoded, day_cos, day_of_week ve day_sin olmadan)...\")\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Adversarial model iÃ§in CatBoost sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± - Parametreler aynÄ± kalabilir\n",
        "cat_adv_params_no_userid_daycos_dayofweek_daysin = {\n",
        "    'objective': 'Logloss',  # Binary classification objective\n",
        "    'eval_metric': 'AUC',\n",
        "    'iterations': 1000,\n",
        "    'learning_rate': 0.05,\n",
        "    'depth': 6,\n",
        "    'random_seed': 42,\n",
        "    'verbose': 0, # Daha fazla bilgi iÃ§in 100 yapabilirsiniz\n",
        "    'task_type': 'GPU' if 'GPU' in str(globals().get('device', '')) else 'CPU',\n",
        "    'early_stopping_rounds': 100\n",
        "}\n",
        "\n",
        "# Kategorik Ã¶zellikleri belirle (user_id_encoded, day_cos, day_of_week ve day_sin olmadan)\n",
        "# CatBoost string/object tÃ¼rÃ¼ndeki kategoriklere doÄŸrudan destek verir.\n",
        "categorical_features_adv_no_userid_daycos_dayofweek_daysin = [col for col in adversarial_features_no_userid_daycos_dayofweek_daysin.columns if adversarial_features_no_userid_daycos_dayofweek_daysin[col].dtype == 'object' or adversarial_features_no_userid_daycos_dayofweek_daysin[col].dtype == 'category']\n",
        "\n",
        "print(f\"   Adversarial model iÃ§in kategorik sÃ¼tunlar (user_id_encoded, day_cos, day_of_week ve day_sin olmadan): {categorical_features_adv_no_userid_daycos_dayofweek_daysin}\")\n",
        "\n",
        "\n",
        "# Ã‡apraz doÄŸrulama ile eÄŸit\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_preds_catboost_no_userid_daycos_dayofweek_daysin = np.zeros(adversarial_data_no_userid_daycos_dayofweek_daysin.shape[0])\n",
        "feature_importances_catboost_no_userid_daycos_dayofweek_daysin = pd.DataFrame(index=adversarial_features_no_userid_daycos_dayofweek_daysin.columns)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(adversarial_features_no_userid_daycos_dayofweek_daysin, adversarial_target_no_userid_daycos_dayofweek_daysin)):\n",
        "    print(f\"\\n   Fold {fold+1}/5\")\n",
        "    X_train_fold, X_val_fold = adversarial_features_no_userid_daycos_dayofweek_daysin.iloc[train_idx], adversarial_features_no_userid_daycos_dayofweek_daysin.iloc[val_idx]\n",
        "    y_train_fold, y_val_fold = adversarial_target_no_userid_daycos_dayofweek_daysin.iloc[train_idx], adversarial_target_no_userid_daycos_dayofweek_daysin.iloc[val_idx]\n",
        "\n",
        "    model = CatBoostClassifier(**cat_adv_params_no_userid_daycos_dayofweek_daysin)\n",
        "\n",
        "    model.fit(X_train_fold, y_train_fold,\n",
        "              eval_set=[(X_val_fold, y_val_fold)],\n",
        "              cat_features=categorical_features_adv_no_userid_daycos_dayofweek_daysin,\n",
        "              early_stopping_rounds=cat_adv_params_no_userid_daycos_dayofweek_daysin['early_stopping_rounds'],\n",
        "              verbose=cat_adv_params_no_userid_daycos_dayofweek_daysin['verbose'])\n",
        "\n",
        "    oof_preds_catboost_no_userid_daycos_dayofweek_daysin[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n",
        "    feature_importances_catboost_no_userid_daycos_dayofweek_daysin[f'fold_{fold+1}'] = model.get_feature_importance() # CatBoost feature importance alma\n",
        "\n",
        "# OOF tahminleri Ã¼zerinden AUC hesapla\n",
        "overall_auc_catboost_no_userid_daycos_dayofweek_daysin = roc_auc_score(adversarial_target_no_userid_daycos_dayofweek_daysin, oof_preds_catboost_no_userid_daycos_dayofweek_daysin)\n",
        "\n",
        "print(f\"\\nâœ… Adversarial model eÄŸitimi tamamlandÄ±!\")\n",
        "print(f\"   Overall Adversarial AUC (CatBoost - user_id_encoded, day_cos, day_of_week ve day_sin olmadan): {overall_auc_catboost_no_userid_daycos_dayofweek_daysin:.6f}\")\n",
        "\n",
        "# Feature importances ortalamasÄ±nÄ± hesapla\n",
        "feature_importances_catboost_no_userid_daycos_dayofweek_daysin['average'] = feature_importances_catboost_no_userid_daycos_dayofweek_daysin.mean(axis=1)\n",
        "feature_importances_catboost_no_userid_daycos_dayofweek_daysin = feature_importances_catboost_no_userid_daycos_dayofweek_daysin.sort_values('average', ascending=False)\n",
        "\n",
        "print(\"\\n   Ã–nemli Ã–zellikler (En YÃ¼ksekten En DÃ¼ÅŸÃ¼ÄŸe - CatBoost - user_id_encoded, day_cos, day_of_week ve day_sin olmadan):\")\n",
        "print(feature_importances_catboost_no_userid_daycos_dayofweek_daysin[['average']].head(20)) # En Ã¶nemli 20 Ã¶zelliÄŸi gÃ¶ster"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:52:39.508212Z",
          "iopub.execute_input": "2025-08-31T12:52:39.508414Z",
          "iopub.status.idle": "2025-08-31T12:53:47.612713Z",
          "shell.execute_reply.started": "2025-08-31T12:52:39.508398Z",
          "shell.execute_reply": "2025-08-31T12:53:47.611996Z"
        },
        "id": "_anZt7-nwN0l"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.ADVERSARIAL MODEL FEATURE IMPORTANCE GÃ–RSELLEÅTÄ°RME (USER_ID_ENCODED, DAY_COS, DAY_OF_WEEK VE DAY_SIN OLMADAN)"
      ],
      "metadata": {
        "id": "HSO6VxRBwN0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 4. ADVERSARIAL MODEL FEATURE IMPORTANCE GÃ–RSELLEÅTÄ°RME (USER_ID_ENCODED, DAY_COS, DAY_OF_WEEK VE DAY_SIN OLMADAN)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ“Š Adversarial model feature importance gÃ¶rselleÅŸtiriliyor (user_id_encoded, day_cos, day_of_week ve day_sin olmadan)...\")\n",
        "\n",
        "# CatBoost modelinden elde edilen ortalama feature importance deÄŸerleri (Ã§Ä±karÄ±lan sÃ¼tunlar olmadan)\n",
        "feature_importance_final = feature_importances_catboost_no_userid_daycos_dayofweek_daysin['average']\n",
        "\n",
        "# Feature importance deÄŸerlerini sÄ±rala\n",
        "sorted_idx_final = feature_importance_final.sort_values(ascending=False).index\n",
        "sorted_importance_final = feature_importance_final[sorted_idx_final]\n",
        "\n",
        "# GÃ¶rselleÅŸtirmeyi yap\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(sorted_idx_final)), sorted_importance_final, align='center')\n",
        "plt.yticks(range(len(sorted_idx_final)), sorted_idx_final)\n",
        "plt.xlabel('Average Feature Importance (Adversarial - Less Features)')\n",
        "plt.title('Adversarial Model Feature Importance (Less Features)')\n",
        "plt.gca().invert_yaxis() # En Ã¶nemli Ã¶zelliÄŸi en Ã¼ste almak iÃ§in y eksenini ters Ã§evir\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Feature importance gÃ¶rselleÅŸtirme tamamlandÄ±!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:53:47.613528Z",
          "iopub.execute_input": "2025-08-31T12:53:47.613778Z",
          "iopub.status.idle": "2025-08-31T12:53:48.153172Z",
          "shell.execute_reply.started": "2025-08-31T12:53:47.613757Z",
          "shell.execute_reply": "2025-08-31T12:53:48.152464Z"
        },
        "id": "VTrXzPU6wN0m"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 6. FINAL MODEL EÄÄ°TÄ°MÄ° (FULL DATA - AZALTILMIÅ Ã–ZELLÄ°K SETÄ°)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ† Final model eÄŸitimi baÅŸlatÄ±lÄ±yor (azaltÄ±lmÄ±ÅŸ Ã¶zellik seti)...\")\n",
        "\n",
        "final_models_reduced = {}\n",
        "\n",
        "# Veriyi hazÄ±rla (Adversarial validation sonrasÄ± kalan Ã¶zellikler)\n",
        "# X_train_modified_3 ve X_test_aligned_modified_3, user_id_encoded, day_cos, day_of_week, day_sin olmadan hazÄ±rlanmÄ±ÅŸtÄ±\n",
        "# Target (y_train_log) hala orijinal train setinden geliyor\n",
        "\n",
        "y_train_final = y_train_log # Log dÃ¶nÃ¼ÅŸÃ¼mlÃ¼ target\n",
        "X_train_final = X_train_modified_3.drop('source', axis=1) # Kaynak sÃ¼tununu Ã§Ä±kar\n",
        "X_test_final = X_test_aligned_modified_3.drop('source', axis=1) # Kaynak sÃ¼tununu Ã§Ä±kar\n",
        "\n",
        "# SÃ¼tunlarÄ±n uyumlu olduÄŸunu kontrol et (adversarial features ile aynÄ± sÃ¼tunlar olmalÄ±)\n",
        "if not X_train_final.columns.equals(X_test_final.columns):\n",
        "    print(\"   âš ï¸ Train ve test Ã¶zellikleri eÅŸleÅŸmiyor! SÃ¼tunlarÄ± hizalanÄ±yor.\")\n",
        "    X_test_final = X_test_final.reindex(columns=X_train_final.columns, fill_value=0) # Fill_value 0 veya uygun bir deÄŸer olabilir\n",
        "\n",
        "print(f\"   ğŸ“Š X_train (Final): {X_train_final.shape}, X_test (Final): {X_test_final.shape}\")\n",
        "\n",
        "\n",
        "# Kategorik sÃ¼tunlarÄ± belirle (artÄ±k user_id_encoded yok)\n",
        "categorical_features_final = [col for col in X_train_final.columns if X_train_final[col].dtype == 'object' or X_train_final[col].dtype == 'category']\n",
        "# duration_segment hala category olabilir, object'e Ã§evirdiÄŸimiz iÃ§in burada object olarak gÃ¶rÃ¼nebilir.\n",
        "\n",
        "print(f\"   ğŸ“Š Final model iÃ§in kategorik sÃ¼tunlar: {categorical_features_final}\")\n",
        "\n",
        "\n",
        "# Modelleri EÄŸit\n",
        "\n",
        "# CatBoost final (azaltÄ±lmÄ±ÅŸ Ã¶zellik seti ile)\n",
        "print(\"\\n   ğŸ± CatBoost final eÄŸitiliyor...\")\n",
        "# CatBoost params are defined earlier as cat_params\n",
        "final_models_reduced['catboost'] = CatBoostRegressor(**cat_params)\n",
        "final_models_reduced['catboost'].fit(\n",
        "    X_train_final,\n",
        "    y_train_final,\n",
        "    cat_features=categorical_features_final,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# LightGBM final (azaltÄ±lmÄ±ÅŸ Ã¶zellik seti ile)\n",
        "print(\"\\n   ğŸ’¡ LightGBM final eÄŸitiliyor...\")\n",
        "# LightGBM params are defined earlier as lgb_params\n",
        "final_models_reduced['lightgbm'] = lgb.LGBMRegressor(**lgb_params)\n",
        "\n",
        "# LightGBM kategorik Ã¶zellikler iÃ§in indeksleri belirle\n",
        "lgb_categorical_indices_final = [X_train_final.columns.get_loc(col) for col in categorical_features_final]\n",
        "\n",
        "# LightGBM iÃ§in kategorik sÃ¼tunlarÄ± int'e Ã§evir\n",
        "X_train_lgb_final = X_train_final.copy()\n",
        "X_test_lgb_final = X_test_final.copy()\n",
        "\n",
        "for col in categorical_features_final:\n",
        "     if X_train_lgb_final[col].dtype == 'object' or X_train_lgb_final[col].dtype == 'category':\n",
        "            X_train_lgb_final[col] = X_train_lgb_final[col].astype(str).astype('category').cat.codes\n",
        "            X_test_lgb_final[col] = X_test_lgb_final[col].astype(str).astype('category').cat.codes\n",
        "\n",
        "\n",
        "final_models_reduced['lightgbm'].fit(\n",
        "    X_train_lgb_final,\n",
        "    y_train_final,\n",
        "    categorical_feature=lgb_categorical_indices_final\n",
        "    # Early stopping callbacks might not be needed for final training on full data\n",
        ")\n",
        "\n",
        "print(\"âœ… Final model eÄŸitimi tamamlandÄ±!\")\n",
        "\n",
        "# Model performanslarÄ±nÄ± kontrol et (Train RMSE - Sadece bilgi amaÃ§lÄ±)\n",
        "print(\"\\nğŸ“ˆ Final model performanslarÄ± (Train RMSE - AzaltÄ±lmÄ±ÅŸ Ã–zellik Seti):\")\n",
        "for name, model in final_models_reduced.items():\n",
        "    if name == 'lightgbm': # LightGBM needs integer-encoded categoricals\n",
        "         train_pred = model.predict(X_train_lgb_final)\n",
        "    else: # CatBoost can handle original types\n",
        "         train_pred = model.predict(X_train_final)\n",
        "    train_rmse = np.sqrt(mean_squared_error(y_train_final, train_pred))\n",
        "    print(f\"{name.upper()}: Train RMSE = {train_rmse:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:53:48.154002Z",
          "iopub.execute_input": "2025-08-31T12:53:48.154214Z",
          "iopub.status.idle": "2025-08-31T12:55:51.598892Z",
          "shell.execute_reply.started": "2025-08-31T12:53:48.154197Z",
          "shell.execute_reply": "2025-08-31T12:55:51.598108Z"
        },
        "id": "jKCgPOtZwN0m"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================================\n",
        "# 7. TAHMÄ°N VE SUBMÄ°SSÄ°ON (AZALTILMIÅ Ã–ZELLÄ°K SETÄ°)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ”® Tahminler yapÄ±lÄ±yor (azaltÄ±lmÄ±ÅŸ Ã¶zellik seti)...\")\n",
        "\n",
        "# Test predictions (azaltÄ±lmÄ±ÅŸ Ã¶zellik seti ile)\n",
        "test_preds_reduced = {}\n",
        "for name, model in final_models_reduced.items():\n",
        "     if name == 'lightgbm': # LightGBM needs integer-encoded categoricals\n",
        "         test_preds_reduced[name] = model.predict(X_test_lgb_final)\n",
        "     else: # CatBoost can handle original types\n",
        "         test_preds_reduced[name] = model.predict(X_test_final)\n",
        "\n",
        "\n",
        "# Ensemble prediction (azaltÄ±lmÄ±ÅŸ Ã¶zellik seti iÃ§in aÄŸÄ±rlÄ±klarÄ± tekrar hesapla veya Ã¶ncekileri kullan)\n",
        "# Basitlik iÃ§in Ã¶nceki aÄŸÄ±rlÄ±klarÄ± kullanalÄ±m, veya val seti oluÅŸturup yeniden hesaplayabiliriz.\n",
        "# Ã–nceki aÄŸÄ±rlÄ±klar eÄŸitimdeki performanslarÄ±na dayanÄ±yordu, ÅŸimdi Ã¶zellik seti deÄŸiÅŸti.\n",
        "# Daha doÄŸru bir yaklaÅŸÄ±m, azaltÄ±lmÄ±ÅŸ Ã¶zellik seti ile bir val seti Ã¼zerinde modelleri deÄŸerlendirip aÄŸÄ±rlÄ±klarÄ± yeniden hesaplamak olur.\n",
        "# Ancak hÄ±zlÄ±ca denemek iÃ§in mevcut aÄŸÄ±rlÄ±klarÄ± kullanalÄ±m.\n",
        "\n",
        "# AÄŸÄ±rlÄ±klar Ã¶nceki eÄŸitimden: weights = {'catboost': 0.337, 'lightgbm': 0.332, 'xgboost': 0.330}\n",
        "# Åimdi 2 modelimiz var, sadece catboost ve lightgbm aÄŸÄ±rlÄ±klarÄ±nÄ± orantÄ±layalÄ±m\n",
        "total_weight_cat_lgb = weights['catboost'] + weights['lightgbm']\n",
        "weights_reduced = {\n",
        "    'catboost': weights['catboost'] / total_weight_cat_lgb,\n",
        "    'lightgbm': weights['lightgbm'] / total_weight_cat_lgb\n",
        "}\n",
        "\n",
        "print(f\"   ğŸ“Š AzaltÄ±lmÄ±ÅŸ Ã–zellik Seti AÄŸÄ±rlÄ±klarÄ±:\")\n",
        "print(f\"      CatBoost: {weights_reduced['catboost']:.3f}\")\n",
        "print(f\"      LightGBM: {weights_reduced['lightgbm']:.3f}\")\n",
        "\n",
        "\n",
        "final_prediction_log_reduced = (weights_reduced['catboost'] * test_preds_reduced['catboost'] +\n",
        "                               weights_reduced['lightgbm'] * test_preds_reduced['lightgbm'])\n",
        "\n",
        "\n",
        "# Convert back to original scale\n",
        "final_prediction_reduced = np.expm1(final_prediction_log_reduced)\n",
        "final_prediction_reduced[final_prediction_reduced < 0] = 0 # ensure no negative predictions\n",
        "\n",
        "\n",
        "# Create model predictions DataFrame\n",
        "model_predictions_df_reduced = pd.DataFrame({\n",
        "    'user_session': test_features_df['user_session'], # Use original test sessions to map back\n",
        "    'session_value': final_prediction_reduced\n",
        "})\n",
        "\n",
        "\n",
        "# ===============================================================================\n",
        "# 8. SUBMÄ°SSÄ°ON DOSYASI OLUÅTURMA (AZALTILMIÅ Ã–ZELLÄ°K SETÄ°)\n",
        "# ===============================================================================\n",
        "\n",
        "print(\"\\nğŸ“ Submission dosyasÄ± oluÅŸturuluyor (azaltÄ±lmÄ±ÅŸ Ã¶zellik seti)...\")\n",
        "\n",
        "# Official template\n",
        "submission_df_reduced = test[['user_session']].drop_duplicates().copy()\n",
        "\n",
        "# Fill leaked data first (leak_map from step 2)\n",
        "if len(leak_map) > 0:\n",
        "    submission_df_reduced['session_value'] = submission_df_reduced['user_session'].map(leak_map)\n",
        "    leaked_count = len(submission_df_reduced) - submission_df_reduced['session_value'].isnull().sum()\n",
        "    print(f\"   ğŸ” {leaked_count} leaked prediction eklendi\")\n",
        "else:\n",
        "    submission_df_reduced['session_value'] = np.nan\n",
        "    leaked_count = 0\n",
        "\n",
        "# Fill remaining with model predictions\n",
        "model_predictions_map_reduced = model_predictions_df_reduced.set_index('user_session')['session_value']\n",
        "submission_df_reduced['session_value'] = submission_df_reduced['session_value'].fillna(\n",
        "    submission_df_reduced['user_session'].map(model_predictions_map_reduced)\n",
        ")\n",
        "\n",
        "filled_by_model = len(submission_df_reduced) - submission_df_reduced['session_value'].isnull().sum() - leaked_count\n",
        "print(f\"   ğŸ¤– {filled_by_model} model prediction eklendi\")\n",
        "\n",
        "\n",
        "# Final check for any remaining NaNs (should not happen if test_unseen_df covers all non-leaked)\n",
        "if submission_df_reduced['session_value'].isnull().sum() > 0:\n",
        "    print(\"   âš ï¸ BoÅŸ deÄŸerler ortalama ile dolduruluyor...\")\n",
        "    submission_df_reduced['session_value'].fillna(y_train.mean(), inplace=True)\n",
        "\n",
        "\n",
        "# Save submission\n",
        "submission_path_reduced = '/content/submission_reduced_features.csv'\n",
        "submission_df_reduced.to_csv(submission_path_reduced, index=False)\n",
        "\n",
        "print(f\"ğŸ‰ BAÅARILI! Submission dosyasÄ± hazÄ±r: {submission_path_reduced}\")\n",
        "print(f\"ğŸ“Š Toplam prediction: {len(submission_df_reduced)}\")\n",
        "# Note: Ensemble RMSE here would require re-calculating on a validation set with reduced features\n",
        "# print(f\"ğŸ“ˆ Ensemble validation RMSE: {ensemble_rmse:.6f}\") # This is from the previous run, not representative of reduced features\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ AzaltÄ±lmÄ±ÅŸ Ã¶zellik seti ile model pipeline tamamlandÄ±!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-31T12:55:51.599784Z",
          "iopub.execute_input": "2025-08-31T12:55:51.600046Z",
          "iopub.status.idle": "2025-08-31T12:55:57.902989Z",
          "shell.execute_reply.started": "2025-08-31T12:55:51.600019Z",
          "shell.execute_reply": "2025-08-31T12:55:57.902301Z"
        },
        "id": "zxy4vxt4wN0n"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}